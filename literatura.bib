@misc{123DCatch,
  author =       {{123D Catch}},
  howpublished = {\url{http://www.123dapp.com/catch}},
  note =         {[mre\v zno; stranica posje\' cena: travanj 2017.]},
}

@ARTICLE{4250461,
  author =       {Y. Y. Schechner and S. K. Nayar and P. N. Belhumeur},
  journal =      {IEEE Transactions on Pattern Analysis and Machine
                  Intelligence},
  title =        {Multiplexing for Optimal Lighting},
  year =         2007,
  volume =       29,
  number =       8,
  pages =        {1339-1354},
  abstract =     {Imaging of objects under variable lighting
                  directions is an important and frequent practice in
                  computer vision, machine vision, and image-based
                  rendering. Methods for such imaging have
                  traditionally used only a single light source per
                  acquired image. They may result in images that are
                  too dark and noisy, e.g., due to the need to avoid
                  saturation of highlights. We introduce an approach
                  that can significantly improve the quality of such
                  images, in which multiple light sources illuminate
                  the object simultaneously from different
                  directions. These illumination-multiplexed frames
                  are then computationally demultiplexed. The approach
                  is useful for imaging dim objects, as well as
                  objects having a specular reflection component. We
                  give the optimal scheme by which lighting should be
                  multiplexed to obtain the highest quality output,
                  for signal-independent noise. The scheme is based on
                  Hadamard codes. The consequences of imperfections
                  such as stray light, saturation, and noisy
                  illumination sources are then studied. In addition,
                  the paper analyzes the implications of shot noise,
                  which is signal-dependent, to Hadamard
                  multiplexing. The approach facilitates practical
                  lighting setups having high directional
                  resolution. This is shown by a setup we devise,
                  which is flexible, scalable, and programmable. We
                  used it to demonstrate the benefit of multiplexing
                  in experiments.},
  keywords =     {Hadamard codes;computer vision;light
                  sources;lighting;multiplexing;object
                  recognition;rendering (computer graphics);Hadamard
                  codes;computer vision;illumination-multiplexed
                  frames;image quality;image-based rendering;lighting
                  directions;machine vision;multiple light
                  sources;object imaging;optimal lighting;specular
                  reflection component;Acoustic reflection;Computer
                  vision;Error correction;Error correction codes;Light
                  sources;Lighting;Machine vision;Optical
                  reflection;Rendering (computer graphics);Stray
                  light;Hadamard codes;Physics-based
                  vision;image-based rendering;multiplexed
                  illumination;photon noise.},
  doi =          {10.1109/TPAMI.2007.1151},
  ISSN =         {0162-8828},
  month =        aug,
}

@INPROCEEDINGS{6247753,
  author =       {M. Gupta and S. K. Nayar},
  booktitle =    {2012 IEEE Conference on Computer Vision and Pattern
                  Recognition},
  title =        {Micro Phase Shifting},
  year =         2012,
  pages =        {813-820},
  abstract =     {We consider the problem of shape recovery for real
                  world scenes, where a variety of global illumination
                  (inter-reflections, subsurface scattering, etc.) and
                  illumination defocus effects are present. These
                  effects introduce systematic and often significant
                  errors in the recovered shape. We introduce a
                  structured light technique called Micro Phase
                  Shifting, which overcomes these problems. The key
                  idea is to project sinusoidal patterns with
                  frequencies limited to a narrow, high-frequency
                  band. These patterns produce a set of images over
                  which global illumination and defocus effects remain
                  constant for each point in the scene. This enables
                  high quality reconstructions of scenes which have
                  traditionally been considered hard, using only a
                  small number of images. We also derive theoretical
                  lower bounds on the number of input images needed
                  for phase shifting and show that Micro PS achieves
                  the bound.},
  keywords =     {image reconstruction;shape recognition;global
                  illumination;high quality reconstructions;image
                  reconstructions;micro phase shifting;real world
                  scenes;shape recovery;sinusoidal
                  patterns;Cameras;Frequency
                  modulation;Lighting;Scattering;Shape;Systematics;Time
                  frequency analysis},
  doi =          {10.1109/CVPR.2012.6247753},
  ISSN =         {1063-6919},
  month =        jun,
}

@INPROCEEDINGS{6248073,
  author =       {Agrawal, Amit and Ramalingam, Srikumar and Taguchi,
                  Yuichi and Chari, Visesh},
  booktitle =    {2012 IEEE Conference on Computer Vision and Pattern
                  Recognition},
  title =        {A theory of multi-layer flat refractive geometry},
  year =         2012,
  pages =        {3346-3353},
  doi =          {10.1109/CVPR.2012.6248073}
}

@Book{ghiglia_pritt_phase_unwrapping,
  author =       {Dennis C. Ghiglia and Mark D. Pritt},
  title =        {Two-Dimensional Phase Unwrapping: Theory,
                  Algorithms, and Software},
  publisher =    {Wiley},
  year =         1998,
  month =        may
}

@book{hartley2003multiple,
  title =        {Multiple view geometry in computer vision},
  author =       {Hartley, Richard and Zisserman, Andrew},
  year =         2003,
  publisher =    {Cambridge university press}
}
